#!/bin/sh
#
# Copyright 2024 Chainguard, Inc.
# Author: Dustin Kirkland <kirkland@chainguard.dev>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

mirror() {
	# Ideally, we'd look at -doc packages only, but it seems that manpages
	# are often shipped in other binary packages, too
	# --doc-only seems to pick up about ~27K manpages, whereas the full run finds about 30K
	#PKGS=$(apk search | grep '\-doc\-' | sed -e "s/\-doc\-.*/\-doc/" | sort -u)
	#TOTAL=$(apk search | grep '\-doc\-' | sed -e "s/\-doc\-.*/\-doc/" | wc -l)
	#
	# So instead, we need to inspect all Wolfi manpages
	apk update
	# We need full wget, for -N option
	apk add wget
	# Get our full package list
	PKGS=$(apk search | sort -u)
	TOTAL=$(apk search | sort -u | wc -l)
	local apk= url=
	local a="x86_64"
	local all_done=0
	local tries=0
	# Create a local package archive mirror
	for apk in $PKGS; do
		url="https://packages.wolfi.dev/os/$a/$apk.apk"
		[ -s "$PKG_DIR/$apk.apk" ] || wget -q --continue -N -O "$PKG_DIR/$apk.apk" "$url"
		# Check package integrity
		tries=0
		while ! apk verify "$PKG_DIR/$apk.apk"; do
			rm -f "$PKG_DIR/$apk.apk"
			wget -q --continue -N -O "$PKG_DIR/$apk.apk" "$url"
			tries=$((tries+1))
			if [ "$tries" -gt 2 ]; then
				echo "ERROR: Integrity error [$apk.apk]" 1>&2
				rm -f "$PKG_DIR/$apk.apk"
				break
			fi
		done
		all_done=$((all_done+1))
		echo "DONE SYNCING: [$all_done / $TOTAL] $((100 * all_done / TOTAL))%: $apk"
	done
}

extract() {
	# FIXME: Sorted by name and version, last package wins, if there are namespace colisions
	local j=0 p=
	local total=$(ls "$PKG_DIR" | wc -l)
	# Need gnutar for tar --wildcards
	apk add gnutar
	for p in $PKG_DIR/*; do
		j=$((j+1))
		tar xf "$p" -C "$DEST_DIR" --wildcards "usr/share/man/*" --overwrite 2>/dev/null
		echo "DONE: [$j / $total] $((100 * j / total))%: $p"
	done
	# Unzip any files in $DEST_DIR, if there are any
	echo "INFO: Unzip any zipped files"
	find "$DEST_DIR" -type f -name "*.gz" | xargs -i gunzip -f {}
}


prune() {
	# Try to prune files that are likely not readable by the "man" command
	local f t
	apk add file
	echo "INFO: Examining and deleting non manpages"
	for f in $(find "$DEST_DIR" -type f); do
		# Best guess at file type
		t=$(file "$f")
		case "$t" in
			*"troff or preprocessor input"*)
				# If 'file' says it's troff format, then good enough, it's a manpage
				continue
			;;
		esac
		if (basename "$f" | grep -q "\.[0-9]"); then
			# Looks like a manpage filename
			continue
		fi
		# Anything else, we'll scrap as not-a-manpage
		# Mostly these are htm, html, pdf, jpg, and gifs that leaked into /usr/share/man somehow...
		echo "$f" >> "$DEST_DIR"/deleted.index
		rm -f "$f"
	done
	touch "$DEST_DIR"/deleted.index
	gzip -9 "$DEST_DIR"/deleted.index
}

permission() {
	# Ensure permissions
	echo "INFO: Fixing permissions..."
	local o="$1"
	if [ -n "$o" ]; then
		chown -R "$o" "$DEST_DIR"
	fi
	find $DEST_DIR -type d | xargs -i chmod 755 {}
	find $DEST_DIR -type f | xargs -i chmod 644 {}
}

compress() {
	# gzip every manpage
	echo "INFO: Zipping all manpages..."
	find "$DEST_DIR" -type f \! -name \*.gz | xargs -i gzip -9 {}
}

symlink() {
	# Handle symlinks
	local dir dest
	echo "INFO: Updating symlinks to gzip files"
	for l in $(find "$DEST_DIR" -type l); do
		dir=$(dirname "$l")
		dest=$(readlink "$l")
		ln -sf "$dest".gz "$l.gz" && rm -f "$l"
	done
	# Delete broken links
	echo "INFO: Deleting broken links"
	find "$DEST_DIR" -type l ! -exec test -e {} \; -print | xargs -i rm -f {}
	find "$DEST_DIR" -type d -empty -delete
}

tarball() {
	# create a static archive for offline usage
	echo "INFO: Creating a static archive..."
	rm -f "$DEST_DIR"/manpages.tar.gz
	tar zcf /tmp/manpages.tar.gz -C "$DEST_DIR"/usr/share man
	mv -f /tmp/manpages.tar.gz "$DEST_DIR"
	# Build our manpage index
	echo "INFO: Building an index..."
	find "$DEST_DIR" | sed -e "s:.*manpages/usr/share/::" | gzip -9 > "$DEST_DIR"/manpages.index.gz
}

usage() {
	echo "
Usage:
$0 [-o|--ownership UID:GID] [-v|--verbose] [STEP]

  Default behavior is to run each of these steps, in this order:
    - mirror               # Takes ~5 hours from scratch, or ~32 minutes to re-sync (36GB)
    - extract              # Takes ~22 minutes (260MB)
    - prune                # Takes ~90 seconds
    - permission           # Takes ~20 seconds
    - compress             # Takes ~40 seconds
    - symlink              # Takes ~40 seconds
    - tarball              # Takes ~4 seconds

  Alternatively, you can specify exactly one of the above steps, to run only that step

"
}


# Establish our destination directory inside of the container where we run
DEST_DIR="manpages"
PKG_DIR="packages"
VERBOSE=0
OWNERSHIP=
cd /root
mkdir -p "$DEST_DIR" "$PKG_DIR"

# Handle command line options
while [ ! -z "$1" ]; do
	case "$1" in
		-v|--verbose)
			VERBOSE=1
			shift
			set -x
			continue
		;;
		-o|--ownership)
			shift
			OWNERSHIP="$1"
			shift
			continue
		;;
		mirror|extract|prune|permission|compress|symlink|tarball)
			# Run the specified step
			cd /root
			$1
			exit 0
		;;
		-h|--help|*)
			usage
			exit 1
		;;
	esac
done

# Otherwise, run all of the steps in order
cd /root
mirror
extract
prune
permission "$OWNERSHIP"
compress
symlink
tarball

# Results in a ~46M manpages.tar.gz with ~25K manpages (97M uncompressed archive)
